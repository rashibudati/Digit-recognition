{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "digit_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "d3bnCB6haJT7",
        "WrFMz-f510SI",
        "kH8Vpbgi10SM",
        "yvsq6qC810SQ",
        "PimlQJK-10SS",
        "MAump8gx10SU",
        "R0Lhhegh10Sr",
        "tLbg6LHy10Sw",
        "TtP1QQt_10TG",
        "F2620hkZ10TL",
        "vGSLqzdU10TX",
        "Z79CWPUU10Td",
        "n1SjI6Vm10Tn",
        "Rx0KGhpn10Tu",
        "KmeP2wRd10UA",
        "146fGmnb10UB",
        "k27VvQKj10UB",
        "Uft2Ta-p10UF",
        "YLu3uujr10UG",
        "hR4IU4EX10Uc",
        "tbm9VXIS10Ud",
        "AbFzgTuw10Ue",
        "XZCKBnH710Uf",
        "zK2dyOx810Ug",
        "upx3oKCw10Uj",
        "MQsjsECc10Uq",
        "Xof9sCDm10U7",
        "SZehIKZd10VB",
        "_U-glFmC10VL",
        "9OEa8I3s10VX",
        "r-0grF5110Vg",
        "Jg5n3C-f10Vm",
        "Ax94ABSs10Vp",
        "jU6nsZ0S10V1",
        "qORgtaAM10Wb",
        "Zh1VwYel10Wh",
        "bK9TP85T10Wi",
        "5wIH3dxg10XP",
        "2BQCP21O10XT"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv6bmqg510Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "### Your code implementation goes here.\n",
        "### Feel free to use as many code cells as needed.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwpIZJa410Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dependencies\n",
        "import os\n",
        "import copy\n",
        "import h5py\n",
        "import _pickle as pickle\n",
        "from glob import glob\n",
        "from random import shuffle\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from IPython.display import SVG\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBFc6wQr10Qq",
        "colab_type": "code",
        "outputId": "219520a9-826d-4a51-b525-9f998a55783c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, BatchNormalization, Convolution2D, Dense, Dropout, MaxPooling2D, Flatten\n",
        "from keras.layers import AveragePooling2D, GlobalAveragePooling2D, concatenate, UpSampling2D, Conv2DTranspose\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbRKSke_10Qu",
        "colab_type": "text"
      },
      "source": [
        "#### Load the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVh8n_DM10Qv",
        "colab_type": "code",
        "outputId": "808f84a7-f8ad-48ff-ae1c-cbef42433f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifmMfj9w10Qx",
        "colab_type": "text"
      },
      "source": [
        "#### Generate synthetic data based on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlnDk3mK10Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_numbers(numbers, number_labels, maxlength=5, digit_sz=(28, 28), return_label=False):\n",
        "    # Attention: Only coded to work with grayscale images at the moment.\n",
        "\n",
        "    # Randomly choose a number length:\n",
        "    img_len = np.random.choice(range(maxlength)) + 1\n",
        "    label = np.empty(5, dtype='str')\n",
        "\n",
        "    #print \"length: \", img_len\n",
        "\n",
        "\n",
        "    # Randomly choose where in our image the sequence of numbers will appear\n",
        "    if img_len < maxlength:\n",
        "        st_point = np.random.choice(maxlength - img_len)\n",
        "    else:\n",
        "        st_point = 0\n",
        "    \n",
        "    #print \"start:\", st_point\n",
        "\n",
        "    charmap = np.zeros(maxlength)\n",
        "    charmap[st_point:st_point + img_len] = 1\n",
        "    \n",
        "    #print \"charmap: \", charmap\n",
        "\n",
        "    # Define a blank character - this will ensure our input image always have the same dimensions\n",
        "    blank_char = np.zeros_like(digit_sz)\n",
        "    blank_lbl = \".\"\n",
        "\n",
        "    # Initialize a blank image with maxlen * digit_dz width and digit_sz height\n",
        "    new_img_len = maxlength * digit_sz[1]\n",
        "    new_img = np.zeros((digit_sz[0], new_img_len))\n",
        "    \n",
        "    # Fill in the image with random numbers from dataset, starting at st_point\n",
        "    for i, b in enumerate(charmap):\n",
        "        if b > 0:\n",
        "            n = np.random.choice(len(numbers))\n",
        "            st_pos = i * digit_sz[1]\n",
        "            new_img[:, st_pos:st_pos + digit_sz[1]] = numbers[n]\n",
        "            label[i] = str(number_labels[n])\n",
        "        else:\n",
        "            label[i] = blank_lbl\n",
        "\n",
        "    if return_label:\n",
        "        return new_img, label\n",
        "\n",
        "    return new_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnT1jjZO10Q1",
        "colab_type": "code",
        "outputId": "6c0f444c-a361-440a-87dd-1f50bdaff6bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "# Create sample to test that function is working\n",
        "img, label = create_numbers(x_train, y_train, return_label=True)\n",
        "plt.imshow(img, cmap='gray')\n",
        "print (label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.' '3' '9' '.' '.']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOdry7B10Q3",
        "colab_type": "text"
      },
      "source": [
        "#### Define a Python Generator to create an unlimited amount of training examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYWbTgJv10Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(numbers, number_labels, batch_size=32):\n",
        "    \"\"\"\n",
        "    This generator receives mnist digits and labels and returns a batch for training\n",
        "\n",
        "    Input:\n",
        "    numbers - array with mnist images.\n",
        "    number_labels - array with mnist labels.\n",
        "\n",
        "    Arguments:\n",
        "    batch_size - size of the mini batch\n",
        "\n",
        "    Output:\n",
        "    X_train and y_train\n",
        "    \"\"\"\n",
        "    while True:  # Loop forever so the generator never terminates\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for batch_sample in range(batch_size):\n",
        "            img, label = create_numbers(numbers, number_labels, return_label=True)\n",
        "            \n",
        "            # Here we will convert the label to a format that Keras API can process:\n",
        "            n_label = np.zeros((5, 11), dtype='int')\n",
        "            for i, digit in enumerate(label):\n",
        "                if digit == \".\":\n",
        "                    n_digit = 10\n",
        "                else:\n",
        "                    n_digit = int(digit)\n",
        "\n",
        "                n_label[i][n_digit] = 1\n",
        "                \n",
        "\n",
        "            images.append(img)\n",
        "            #labels.append(label)\n",
        "            labels.append(n_label)\n",
        "\n",
        "        X_train = np.array(images)\n",
        "        if len(X_train.shape) == 3:\n",
        "            X_train = np.expand_dims(X_train, -1)\n",
        "\n",
        "        y_temp = np.array(labels)\n",
        "        \n",
        "        y1 = y_temp[:, 0, :]\n",
        "        y2 = y_temp[:, 1, :]\n",
        "        y3 = y_temp[:, 2, :]\n",
        "        y4 = y_temp[:, 3, :]\n",
        "        y5 = y_temp[:, 4, :]\n",
        "\n",
        "        yield X_train, [y1, y2, y3, y4, y5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90sl5owA10Q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_label(label):\n",
        "    n_label = \"\"\n",
        "    for digit in label:\n",
        "        if np.argmax(digit) == 10:\n",
        "            n_digit = \".\"\n",
        "        else:\n",
        "            n_digit = str(np.argmax(digit))\n",
        "        n_label += n_digit\n",
        "    return n_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzkLDo6f10Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create samples to test the generator\n",
        "i = 0\n",
        "for a, b in generator(x_train, y_train, batch_size=16): \n",
        "    test_imgs = a\n",
        "    test_lbls = b\n",
        "    \n",
        "    i += 1\n",
        "    \n",
        "    if i > 1:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "bETN8VQn10Q_",
        "colab_type": "code",
        "outputId": "67abc70d-3922-4c61-936d-a09c85bfa217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        }
      },
      "source": [
        "rows_to_plot = 8\n",
        "cols_to_plot = 2\n",
        "\n",
        "f = plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i in range(16):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.title(convert_label(np.vstack((test_lbls[0][i], test_lbls[1][i], test_lbls[2][i], \n",
        "                                                test_lbls[3][i],test_lbls[4][i]))))\n",
        "    plt.imshow(test_imgs[i][:, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzEAAANhCAYAAADXGDV3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x864 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7LZbk0U10RC",
        "colab_type": "text"
      },
      "source": [
        "#### End-to-end model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNVOr9Ac10RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on Model from: http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf\n",
        "\n",
        "def get_model(input_shape=(28, 28*5, 3), p=0.5, n_class=11):\n",
        "\n",
        "    inputs = Input(((input_shape[0], input_shape[1], input_shape[2])))\n",
        "    \n",
        "    x = BatchNormalization()(inputs)\n",
        "    x = Convolution2D(48, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p/4)(x)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(64, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p/4)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(128, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p/2)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(160, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p/2)(x)\n",
        "\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "#     x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "#     x = Dropout(p)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p)(x)\n",
        "    \n",
        "    # I had to remove this part because the input size we have is too small for a network this deep.\n",
        "    # Another alternative would have been change the maxpool strides.\n",
        "    \n",
        "    #x = BatchNormalization()(x)\n",
        "    #x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    #x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    #x = Dropout(p)(x)\n",
        "\n",
        "    #x = BatchNormalization()(x)\n",
        "    #x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    #x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    #x = Dropout(p)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x) # I also reduced the number of activations\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    \n",
        "    c1 = Dense(n_class, activation='softmax')(x)\n",
        "    c2 = Dense(n_class, activation='softmax')(x)\n",
        "    c3 = Dense(n_class, activation='softmax')(x)\n",
        "    c4 = Dense(n_class, activation='softmax')(x)\n",
        "    c5 = Dense(n_class, activation='softmax')(x)\n",
        "    \n",
        "    output = [c1, c2, c3, c4, c5]\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GaLr14c10RH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_output(model_output):\n",
        "    model_output = np.array(model_output).swapaxes(0, 1)\n",
        "    labels = []\n",
        "    for output in model_output:\n",
        "        label = convert_label(output)\n",
        "        labels.append(label)\n",
        "\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxpI_2T10RK",
        "colab_type": "code",
        "outputId": "642b43bd-5eb9-4641-e35f-3e47667175e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "model = get_model(input_shape=(28, 28*5, 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tARKusp510RN",
        "colab_type": "code",
        "outputId": "51be8b98-5c4f-4302-dabd-8f8a10542877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 140, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 140, 1)   4           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 140, 48)  1248        batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 14, 70, 48)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 14, 70, 48)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 14, 70, 48)   192         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 14, 70, 64)   76864       batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 13, 69, 64)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 13, 69, 64)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 13, 69, 64)   256         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 13, 69, 128)  204928      batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 68, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 12, 68, 128)  0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 12, 68, 128)  512         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 12, 68, 160)  512160      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 11, 67, 160)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 11, 67, 160)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 11, 67, 160)  640         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 11, 67, 192)  768192      batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 10, 66, 192)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 10, 66, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 126720)       0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         129762304   flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         1049600     dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 132,433,275\n",
            "Trainable params: 132,432,473\n",
            "Non-trainable params: 802\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzZdwVZk10RY",
        "colab_type": "text"
      },
      "source": [
        "#### Overfit on small sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zInQPyap10RZ",
        "colab_type": "code",
        "outputId": "56e2ed8f-4ece-4079-e542-503d393628af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Overfit small data to ensure model can learn\n",
        "optimizer = Adam(lr=1e-3)\n",
        "model.compile(optimizer, loss='categorical_crossentropy')\n",
        "model.fit(test_imgs, test_lbls, epochs=50, verbose=0)\n",
        "teste_out = model.predict(test_imgs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd3AGcEw10Rc",
        "colab_type": "code",
        "outputId": "3ea37974-daa1-4004-f7c9-b6a55536b212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "output = convert_output(teste_out)\n",
        "\n",
        "rows_to_plot = 4\n",
        "cols_to_plot = 2\n",
        "\n",
        "f = plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, (pred, img) in enumerate(zip(output, test_imgs)):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.title(\"Predicted: \" + pred)\n",
        "    plt.imshow(img[:, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5d75d1e2871e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows_to_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_to_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1365\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     raise ValueError(\n\u001b[1;32m     59\u001b[0m                         (\"num must be 1 <= num <= {maxn}, not {num}\"\n\u001b[0;32m---> 60\u001b[0;31m                         ).format(maxn=rows*cols, num=num))\n\u001b[0m\u001b[1;32m     61\u001b[0m                 self._subplotspec = GridSpec(\n\u001b[1;32m     62\u001b[0m                         rows, cols, figure=self.figure)[int(num) - 1]\n",
            "\u001b[0;31mValueError\u001b[0m: num must be 1 <= num <= 8, not 9"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAFrCAYAAADYXuFKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX-sILkD10Rg",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5TzT60Z10Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(input_shape=(28, 28*5, 1))\n",
        "optimizer = Adam(lr=1e-3)\n",
        "model.compile(optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "trn_generator = generator(x_train, y_train, batch_size=128)\n",
        "val_generator = generator(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn0HfFqk10Rm",
        "colab_type": "code",
        "outputId": "d046ef5c-5507-4465-a1be-75c7cdb2a848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "source": [
        "model.fit_generator(trn_generator,\n",
        "                    epochs=10,\n",
        "                    steps_per_epoch=780,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=780,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "581/780 [=====================>........] - ETA: 1:44 - loss: 50.3524 - dense_10_loss: 9.8972 - dense_11_loss: 14.7184 - dense_12_loss: 12.6280 - dense_13_loss: 9.9056 - dense_14_loss: 3.2031 - dense_10_categorical_accuracy: 0.3860 - dense_11_categorical_accuracy: 0.0868 - dense_12_categorical_accuracy: 0.2165 - dense_13_categorical_accuracy: 0.3854 - dense_14_categorical_accuracy: 0.8013"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3396f760311f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m780\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0irbTdiF10Rq",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1N5BOZr10Rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a test set with 1,000 examples\n",
        "\n",
        "i = 0\n",
        "for test_set, test_labels in generator(x_train, y_train, batch_size=1000): \n",
        "\n",
        "    i += 1\n",
        "\n",
        "    if i > 1:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXcQK1Rz10Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(test_set, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TdZpqvY10Ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pv1_J2X10R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred_labels = convert_output(test_pred)\n",
        "test_true_labels = convert_output(test_labels)\n",
        "\n",
        "# print(test_pred_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJsSYb7a10R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 800\n",
        "print (\"Predicted: \", test_pred_labels[ref])\n",
        "print (\"Ground Truth: \", test_true_labels[ref])\n",
        "\n",
        "plt.imshow(test_set[ref][:, :, 0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPhoNDEn10R5",
        "colab_type": "text"
      },
      "source": [
        "We can see that the individual predictions are above 99.5% for all digits, but the true error will be higher than that since any digit that we misclassify will be enough to render our prediction useless.\n",
        "\n",
        "So we need to evaluate the whole prediction as either right or wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or0KgOhg10R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = accuracy_score(test_true_labels, test_pred_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVPxj6_U10R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( \"Accuracy: \", accuracy*100, \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xQl61RR10R_",
        "colab_type": "text"
      },
      "source": [
        "#### Save  and load our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wIQ6h2b10SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('step1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m__wgWRw10SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('step1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--fqUjNG7B-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "print('Label: ', y_train[100])\n",
        "plt.imshow(x_train[100], cmap=plt.cm.bone);\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9BDCxoJgpFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahD0_oBE9YPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils.perspective import four_point_transform\n",
        "from imutils import contours\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMshA_n189sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread(\"m.png\")\n",
        "\n",
        "import numpy as np\n",
        "# pre-process the image by resizing it, converting it to\n",
        "# graycale, blurring it, and computing an edge map\n",
        "image1 = cv2.resize(image, (28*5, 28))\n",
        "\n",
        "gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "edged = cv2.Canny(blurred, 50, 200, 255)\n",
        "plt.imshow(gray, cmap=plt.cm.bone)\n",
        "gray.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBfkezFN89w0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(gray.reshape([-1,28,140,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISaJNt2e9WlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred_labels = convert_output(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf_dK3R-89qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_pred_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqYqZ4DD7Cne",
        "colab_type": "code",
        "outputId": "92db8f34-6edc-4189-cad7-8a0baf96cb50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ref = 0\n",
        "print (\"Predicted: \", test_pred_labels[ref])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  23288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d3bnCB6haJT7"
      },
      "source": [
        "#### New model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDuMoKdvaVWa",
        "colab_type": "code",
        "outputId": "2901d517-460e-4d95-9b83-0f04f28157ed",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed953ac4-7885-4a93-83fa-71b0c5019841\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ed953ac4-7885-4a93-83fa-71b0c5019841\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving step2.h5 to step2.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TzPEI9Wgj8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on Model from: http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf\n",
        "\n",
        "def get_new_model(input_shape=(54, 54, 3), p=0.5, n_class=11, n_len=6):\n",
        "\n",
        "    inputs = Input(((input_shape[0], input_shape[1], input_shape[2])))\n",
        "    \n",
        "    x = BatchNormalization()(inputs)\n",
        "    x = Convolution2D(48, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p/4)(x)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(64, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p/4)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(128, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p/2)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(160, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p/2)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p)(x)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(3072, activation='relu')(x)\n",
        "    x = Dense(3072, activation='relu')(x)\n",
        "\n",
        "    l = Dense(n_len, activation='softmax')(x)\n",
        "    c1 = Dense(n_class, activation='softmax')(x)\n",
        "    c2 = Dense(n_class, activation='softmax')(x)\n",
        "    c3 = Dense(n_class, activation='softmax')(x)\n",
        "    c4 = Dense(n_class, activation='softmax')(x)\n",
        "    c5 = Dense(n_class, activation='softmax')(x)\n",
        "    \n",
        "    output = [l, c1, c2, c3, c4, c5]\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-8WP32Agsf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = get_new_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzsO68K_gsc7",
        "colab_type": "code",
        "outputId": "60382d22-6d18-434d-e9e8-b8a9cbcc9a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 54, 54, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 54, 54, 3)    12          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 54, 54, 48)   3648        batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 27, 27, 48)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 27, 27, 48)   0           max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 27, 27, 48)   192         dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 27, 27, 64)   76864       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 26, 26, 64)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 26, 26, 64)   0           max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 26, 26, 64)   256         dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 26, 26, 128)  204928      batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 13, 13, 128)  0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 13, 13, 128)  0           max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 13, 13, 128)  512         dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 13, 13, 160)  512160      batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 12, 12, 160)  0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 12, 12, 160)  0           max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 12, 12, 160)  640         dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 12, 12, 192)  768192      batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 6, 6, 192)    0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 6, 6, 192)    0           max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 6, 6, 192)    768         dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 6, 6, 192)    921792      batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 5, 5, 192)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 5, 5, 192)    0           max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 5, 5, 192)    768         dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 5, 5, 192)    921792      batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 2, 2, 192)    0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 2, 2, 192)    0           max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 2, 2, 192)    768         dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 2, 2, 192)    921792      batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 1, 1, 192)    0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 1, 1, 192)    0           max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 192)          0           dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 3072)         592896      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 3072)         9440256     dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 6)            18438       dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 11)           33803       dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 11)           33803       dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 11)           33803       dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 11)           33803       dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 11)           33803       dense_16[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 14,555,689\n",
            "Trainable params: 14,553,731\n",
            "Non-trainable params: 1,958\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU3GZCStgsau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_convert_output(model_output):\n",
        "    l = model_output[0]\n",
        "    digits = np.array(model_output[1:]).swapaxes(0, 1)\n",
        "    labels = []\n",
        "    for i in range(len(l)):\n",
        "        label = new_convert_label(([l[i]], digits[i, 0, :], digits[i, 1, :],\n",
        "                                  digits[i, 2, :], digits[i, 3, :], digits[i, 4, :]))\n",
        "        labels.append(label)\n",
        "\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmV6yshdicHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_convert_label(label):\n",
        "    l = label[0]\n",
        "    labels = label[1:]\n",
        "    n_label = \"\"\n",
        "    for digit in labels:\n",
        "        if np.argmax(digit) == 0:\n",
        "            n_digit = \"\"\n",
        "        elif np.argmax(digit) == 10:\n",
        "            n_digit = \"0\"\n",
        "        else:\n",
        "            n_digit = str(np.argmax(digit))\n",
        "        n_label += n_digit\n",
        "    return n_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs8kQrrugxgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=1e-3)\n",
        "new_model.compile(optimizer, loss='categorical_crossentropy')\n",
        "# new_model.fit(test_imgs, test_lbls, epochs=1000, verbose=0)\n",
        "# teste_out = new_model.predict(test_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsJ8CD_RgxkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = get_new_model()\n",
        "optimizer = Adam(lr=1e-3)\n",
        "new_model.compile(optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c0Hdb5wgxeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.load_weights('step2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k2pAdN6iaJUb",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils.perspective import four_point_transform\n",
        "from imutils import contours\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0d97f7a3-f532-4e6d-e901-4376bd229a17",
        "id": "FY-OZaf1aJUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "image = cv2.imread(\"1.png\")\n",
        "\n",
        "import numpy as np\n",
        "# pre-process the image by resizing it, converting it to\n",
        "# graycale, blurring it, and computing an edge map\n",
        "image2 = cv2.resize(image, (54, 54))\n",
        "\n",
        "gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "edged = cv2.Canny(blurred, 50, 200, 255)\n",
        "plt.imshow(image2, cmap=plt.cm.bone)\n",
        "image2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, 54, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUjR6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BLd1_03BaJUs",
        "colab": {}
      },
      "source": [
        "test_pred2 = new_model.predict(image2.reshape([-1,54,54,3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kw7ZkqQeaJUz",
        "colab": {}
      },
      "source": [
        "test_pred_labels2 = new_convert_output(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b8687096-38eb-4700-c2a1-0b23ccbbc320",
        "id": "kvdLKwNeaJU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_pred_labels2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3321']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5dfb7e2c-bdf5-4c8f-fc42-164c123840eb",
        "id": "7nMJmK4waJVE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ref = 0\n",
        "print (\"Predicted: \", test_pred_labels[ref])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  3321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugydhIqLjG77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsxOCc1gjH9W",
        "colab_type": "text"
      },
      "source": [
        "#Not needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrFMz-f510SI",
        "colab_type": "text"
      },
      "source": [
        "### Question 1\n",
        "_What approach did you take in coming up with a solution to this problem?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxbdsDdy10SJ",
        "colab_type": "text"
      },
      "source": [
        "**Answer:** \n",
        "\n",
        "Before I started coding the first step, it was good to think about the purpose of the synthetic dataset in the pipeline. Generally speaking, in an academic study, the datasets are somewhat standardized, and benchmarks for new models are established on top of this \"clean data\" - in commercial applications, however, that is not the norm. Labeled data to train your models are expensive to obtain, and the best approach is to often train a model in a similar dataset if available and then fine-tune it to the new problem you are trying to solve.\n",
        "\n",
        "Having said that, we want to make our synthetic data as close as possible to the data you expect to feed your model when you fine-tune it. So the obvious thing is to have a look at a few images from the SVHN dataset and then come up with a \"proxy\" synthetic dataset.\n",
        "\n",
        "Upon exploring the SVHN dataset we notice that the numbers are not always exactly centered, and they appear in several different colors, skew and rotation. \n",
        "\n",
        "Our synthetic dataset was created by first randomly choosing a number length between 1 and 5 digits, followed by another random decision as to where in the image we would like the sequence to appear (centered, skip first character, etc...) and then finally randomly pulling N digits from the MNIST training dataset.\n",
        "\n",
        "When creating the labels I decided to use \".\" to represent blank spaces to help when visually investigating the dataset.\n",
        "\n",
        "Examples were thoroughly provided on the notebook.\n",
        "\n",
        "\n",
        "** End-To-End Deep CNN model **\n",
        "\n",
        "In the project instructions there were several recommended approaches to create a pipeline to solve our problem, the one that I found more interesting is based on [[1]](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf \"Multi-digit Number Recognition from Street View\n",
        "Imagery using Deep Convolutional Neural Networks\") where the authors proposed an end-to-end solution to this problem that does not involve breaking down the problem into localization, segmentation and recognition in different steps.\n",
        "\n",
        "As Goodfellow et al. describe in their work:\n",
        ">Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery.\n",
        "Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels\n",
        "\n",
        "Inspired by the great results they displayed in their study and an elegant solution that would learn from these images without the assistance of a digit localizer, I decided to replicate their work for this pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH8Vpbgi10SM",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9BX2O5W10SN",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "The model proposed by Goodfellow et al. is the following:\n",
        ">Our best architecture consists of eight convolutional hidden layers, one locally connected hidden layer, and two densely connected hidden layers. All connections are feedforward and go from one layer to the next (no skip connections). The first hidden layer contains maxout units (Goodfellow et al., 2013) (with three filters per unit) while the others contain rectifier units (Jarrett et al., 2009; Glorot et al., 2011). The number of units at each spatial location in each layer is [48, 64, 128, 160] for the first four layers and 192 for all other locally connected layers. The fully connected layers contain 3,072 units each.\n",
        "\n",
        "\n",
        "The dimensions of our synthetic images are 28 x 140 x 1 (MNIST dimensions are 28 x 28 and we concatenated up to 5 of them together) and the 11 layer the authors used in their work was too deep for our data, so some modification was needed.\n",
        "\n",
        "I could have just removed a few of the MaxPooling layers, but since this problem was simpler to solve I decided to completely remove the last two convolutional blocks and the first locally connected hidden layer. I also included BatchNormalization before every convolutional layer and reduced the number of activations on the fully connected layers to 1024.\n",
        "\n",
        "The final version can be seen below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "S-FE_Be410SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvsq6qC810SQ",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fS8cMPf10SR",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "The first step was to create a function that would output an image of up to 5 digits, randomly extracted from the MNIST dataset and it's label - For the sake of visualization I decided to use a \".\" to represent blank cells, that way we can validate if the position of the prediction is in the right place. The full implementation can be found in this notebook, under the function **create_numbers**.\n",
        "\n",
        "The next step was to create a python generator that would output several of these images and their labels in a format that Keras API would be able to process. This can be found under the function **generator** provided above.\n",
        "\n",
        "The python generator leverages the **create_numbers** function in order to provide us with a virtually unlimited training set. A thorough explanation of how it works can be seen below:\n",
        "\n",
        "```python\n",
        "def generator(numbers, number_labels, batch_size=32):\n",
        "\n",
        "    while True:  # Loop forever so the generator never terminates\n",
        "    \n",
        "        # define blank lists that will be filled in the for loop\n",
        "        images = []\n",
        "        labels = []\n",
        "        \n",
        "        # loop for as many iterations as you want your batch size to be\n",
        "        for batch_sample in range(batch_size):\n",
        "            img, label = create_numbers(numbers, number_labels, return_label=True)\n",
        "            \n",
        "            # After calling our create_numbers function we are basically done, but unfortunately\n",
        "            # Keras needs the labels to be one-hot encoded so from here on we just convert\n",
        "            # our labels into arrays of n_label dimensions that has 1 for the column to which class\n",
        "            # the sample belongs and 0 everywhere else.\n",
        "            \n",
        "            # define a label set with 5 rows (number of digits) and 11 columns (0-9 digits + blank)\n",
        "            n_label = np.zeros((5, 11), dtype='int')\n",
        "            for i, digit in enumerate(label):\n",
        "                if digit == \".\":\n",
        "                    n_digit = 10\n",
        "                else:\n",
        "                    n_digit = int(digit)\n",
        "\n",
        "                n_label[i][n_digit] = 1\n",
        "                \n",
        "        # in the function we manipulate the numbers furter to ensure compatibility with Keras' API \n",
        "\n",
        "        # return randomly generated image and list of one-hot encoded labels\n",
        "        yield X_train, [y1, y2, y3, y4, y5]\n",
        "```\n",
        "\n",
        "Samples were provided right after each function was created.\n",
        "\n",
        "With this generator we can have an unlimited amount of data to train our model. My first step was to train the model with a very small dataset (8 samples) that allowed me to quickly identify mistakes and fix the model without the burden of waiting for the long training time. At this stage I also made sure the model could overfit the small sample.\n",
        "\n",
        "When you have unlimited training data, the only problem you need to worry about is for how long to train. In general, it's difficult to end up over fitting to your data if your synthetic data is carefully crafted like ours.\n",
        "\n",
        "I used a mini-batch size of 128 samples, a number large enough that also fit in my GPU memory, and decided that every epoch should consist of approximately 100k images (as it would in theory allow the model to see each possibility at least once, although in practice we can't be sure) after just two epochs of training our validation accuracy was already above 99.5% for each individual digit so I stopped training.\n",
        "\n",
        "Measuring accuracy in that way is not recommended, because if our output has any of the digits wrong, the information is useless. So I converted the predicted digits back to string and compared with the ground truth strings generated for 1,000 random images from the validation set and the accuracy this time was 98.5%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njvrCtwB10SR",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "## Step 2: Train a Model on a Realistic Dataset\n",
        "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PimlQJK-10SS",
        "colab_type": "text"
      },
      "source": [
        "### Implementation\n",
        "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dMPq4Pm10SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "### Your code implementation goes here.\n",
        "### Feel free to use as many code cells as needed.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAump8gx10SU",
        "colab_type": "text"
      },
      "source": [
        "#### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fX7VZYM10SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/home/bruno/Documents/eLearning/udacity/Digit-Recognition'\n",
        "dataset_path = '/media/bruno/Data/Datasets/SVHN/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6on6t4-Z10SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_filenames = glob(dataset_path + '/train/*.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CKY9AW10Sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows_to_plot = 5\n",
        "cols_to_plot = 5\n",
        "\n",
        "f = plt.figure(figsize=(16, 4))\n",
        "\n",
        "for i, fn in enumerate(np.random.choice(len(train_filenames), rows_to_plot * cols_to_plot)):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.imshow(Image.open(train_filenames[fn], mode='r'))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqzRrO_B10Sc",
        "colab_type": "text"
      },
      "source": [
        "From this first exploration we can see that it's going to be a lot harder to train a model that performs well on this dataset. The numbers appear in different colors, distortions, skews and conditions (e.g. blurred images).\n",
        "\n",
        "Differently than our synthetic dataset, street numbers in real life don't have a random distribution like the ones we created. Most streets are short ones and we should expect to see a lot more numbers with less 3 or less digits than with 4 or 5.\n",
        "\n",
        "Let's take a look at how the length of digits is distributed in our training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6UQVknm10Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readAndSaveMetadata(filepath):\n",
        "    # Forked from https://discussions.udacity.com/t/how-to-deal-with-mat-files/160657/3\n",
        "    \n",
        "    # Load the given MatLab file\n",
        "    f = h5py.File(filepath, 'r')\n",
        "    fn = filepath.split('/')[-1]\n",
        "    \n",
        "    # Create our empty dictionary\n",
        "    metadata= {}\n",
        "    metadata['height'] = []\n",
        "    metadata['label'] = []\n",
        "    metadata['left'] = []\n",
        "    metadata['top'] = []\n",
        "    metadata['width'] = []\n",
        "    \n",
        "    # define a function to pass to h5py's visititems() function\n",
        "    def print_attrs(name, obj):\n",
        "        vals = []\n",
        "        if obj.shape[0] == 1:\n",
        "            vals.append(obj[0][0])\n",
        "        else:\n",
        "            for k in range(obj.shape[0]):\n",
        "                vals.append(f[obj[k][0]][0][0])\n",
        "        metadata[name].append(vals)\n",
        "    \n",
        "    # Add information to metadata\n",
        "    for item in f['/digitStruct/bbox']:\n",
        "        f[item[0]].visititems(print_attrs)\n",
        "    \n",
        "    # Save to a pickle file\n",
        "    pickle_file = fn + '.pickle'\n",
        "    try:\n",
        "      pickleData = open(pickle_file, 'wb')\n",
        "      pickle.dump(metadata, pickleData, pickle.HIGHEST_PROTOCOL)\n",
        "      pickleData.close()\n",
        "    except Exception as e:\n",
        "      print 'Unable to save data to', pickle_file, ':', e\n",
        "      raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NHFsypB10Sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#readAndSaveMetadata(dataset_path + 'train_digitStruct.mat')\n",
        "#readAndSaveMetadata(dataset_path + 'test_digitStruct.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBfrp5cb10Si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('train_digitStruct.mat.pickle', 'r')\n",
        "trn_data = pickle.load(f)\n",
        "trn_data = pd.DataFrame.from_dict(trn_data)\n",
        "\n",
        "f = open('test_digitStruct.mat.pickle', 'r')\n",
        "tst_data = pickle.load(f)\n",
        "tst_data = pd.DataFrame.from_dict(tst_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkd7AIWb10Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_label_len = []\n",
        "for label in trn_data['label']:\n",
        "    label_len = len(label)\n",
        "    trn_label_len.append(label_len)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PO35BcB10So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count, bins, patches = plt.hist(trn_label_len, bins=range(1,7), normed=True )\n",
        "\n",
        "plt.plot(np.concatenate(([0], np.cumsum(count))), 'r' )\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('House Number Length Distribution')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdJm9VIu10Sq",
        "colab_type": "text"
      },
      "source": [
        "As we expected over 95% of our sample has 3 or less digits. This will probably impact the performance of our algorithm when detecting longer street numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Lhhegh10Sr",
        "colab_type": "text"
      },
      "source": [
        "#### Image pre-processing\n",
        "\n",
        "The authors of the paper we are basing this work on have suggested the following pre-processing steps:\n",
        "\n",
        "- Based on the provided bounding boxes, find another box that will contain all digits on the image\n",
        "\n",
        "- Expand this bounding box by 30% in each direction and crop the image to this bounding box\n",
        "\n",
        "- Resize the cropped image to 64 x 64 pixels\n",
        "\n",
        "- Random crop a 54 x 54 sample from the cropped image\n",
        "\n",
        "This will be implemented inside a generate_crop function that will later on be called by our generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9DX-_DC10Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_crop(filepath, dataframe, expand_by=0.3, verbose=0, crop_sz=(64, 64), random_crop=True):\n",
        "    \"\"\"\n",
        "    This function expects a filepath of an image and will return either a 64 x 64 crop\n",
        "    or a 54 x 54 random crop of the street number depending on the random_crop parameter.\n",
        "    \n",
        "    \"\"\"\n",
        "    # 1 - open the image and store img dimensions\n",
        "    img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_h = img.shape[0]\n",
        "    img_w = img.shape[1]\n",
        "\n",
        "    if verbose>0:\n",
        "        print \"img_h: \", img_h, \"    img_w: \", img_w, \"\\n\"\n",
        "\n",
        "    # 2 - find bounding box for whole street number\n",
        "    fn = filepath.split('/')[-1].split('.')[0]\n",
        "\n",
        "    left = np.min(dataframe.loc[int(fn) - 1].left)\n",
        "    top = np.min(dataframe.loc[int(fn) - 1].top)\n",
        "    bottom = (np.max(dataframe.loc[int(fn) - 1].top) + np.max(dataframe.loc[int(fn) - 1].height))\n",
        "    right = (np.max(dataframe.loc[int(fn) - 1].left) + np.max(dataframe.loc[int(fn) - 1].width))\n",
        "\n",
        "    if verbose>0:\n",
        "        print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
        "\n",
        "    # 3 - Expand bounding box by X%\n",
        "    mid_x = (left + right) // 2\n",
        "    mid_y = (top + bottom) // 2\n",
        "    new_h = np.abs(bottom - top) * (1 + expand_by)\n",
        "    new_w = np.abs(right - left) * (1 + expand_by)\n",
        "\n",
        "    if verbose>0:\n",
        "        print \"mid_x: \", mid_x, \"    mid_y: \", mid_y, \"    new_h: \", new_h, \"    new_w: \", new_w, \"\\n\"\n",
        "    \n",
        "    # New points will be determined by the calculations above and the original image size\n",
        "    left = np.max((0, mid_x - new_w // 2)).astype(np.uint)\n",
        "    right = np.min((img_w, mid_x + new_w // 2)).astype(np.uint)\n",
        "    top = np.max((0, mid_y - new_h // 2)).astype(np.uint)\n",
        "    bottom = np.min((img_h, mid_y + new_h // 2)).astype(np.uint)\n",
        "\n",
        "    if verbose>0:\n",
        "        print \"n_left: \", left, \"    n_right: \", right, \"    n_top: \", top, \"    n_bottom: \", bottom, \"\\n\"\n",
        "    \n",
        "    # 4 - Crop image within bounding box\n",
        "    cropped = img[top:bottom, left:right, :].copy()\n",
        "\n",
        "    # 5 - Rescale to 64 x 64\n",
        "    rescaled = cv2.resize(cropped, crop_sz)\n",
        "    \n",
        "    if random_crop:\n",
        "        dx = np.random.randint(0, 10)\n",
        "        dy = np.random.randint(0, 10)\n",
        "        rescaled = rescaled[dx:dx+54, dy:dy+54, :]\n",
        "    \n",
        "    return rescaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9NV06Ag10Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "items_to_plot = 10\n",
        "\n",
        "f = plt.figure(figsize=(12, 12))\n",
        "\n",
        "i = 0\n",
        "for fn in np.random.choice(len(train_filenames), items_to_plot):\n",
        "    # Plot original\n",
        "    f.add_subplot(items_to_plot // 2, 4, i+1)\n",
        "    plt.title('Original Image')\n",
        "    plt.imshow(Image.open(train_filenames[fn], mode='r'))\n",
        "    plt.axis('off')\n",
        "    i += 1\n",
        "\n",
        "    # Plot cropped\n",
        "    f.add_subplot(items_to_plot // 2, 4, i+1)\n",
        "    plt.title('Random Crop')\n",
        "    plt.imshow(generate_crop(train_filenames[fn], trn_data))\n",
        "    plt.axis('off')\n",
        "    i += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLbg6LHy10Sw",
        "colab_type": "text"
      },
      "source": [
        "#### Test run with the previous model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x4mkvYe10Sw",
        "colab_type": "text"
      },
      "source": [
        "Now that we can isolate the numbers from the rest of the image, we can pass this image to our first model and see how it performs. In order to do that we will need to scale them to 28 x 140 and grayscale - since this is how our model was trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOxMhdM_10Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img = generate_crop(train_filenames[35], trn_data, crop_sz=(140, 28), random_crop=False)\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2GRAY)\n",
        "plt.imshow(test_img, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6BEylj010S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img = np.expand_dims(test_img, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH_V-Rx010S3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(np.expand_dims(test_img, 0))\n",
        "test_pred_labels = convert_output(test_pred)\n",
        "print \"Predicted: \", test_pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoY7wKC-10S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 35\n",
        "test_img = generate_crop(train_filenames[ref], trn_data, crop_sz=(140, 28), random_crop=False)\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2GRAY)\n",
        "test_img = np.expand_dims(test_img, -1)\n",
        "test_pred = model.predict(np.expand_dims(test_img, 0))\n",
        "test_pred_labels = convert_output(test_pred)\n",
        "\n",
        "plt.imshow(test_img[:, :, 0], cmap='gray')\n",
        "plt.title(\"Predicted label: \" + test_pred_labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvN1Wdr410S7",
        "colab_type": "text"
      },
      "source": [
        "That's not a good indicator, I personally chose the above image as i expected it to be easier, as it's somewhat similar to what we have been using so far. Unfortunately because the two datasets have labels created in very different ways, it would be too time consuming to develop a compatibility layer just to prove that our current model is not doing a good job.\n",
        "\n",
        "If we had reasons to believe it would perform well, it would probably be worth to invest time into doing that, but if it fails on the \"easy\" images, we will make a better use of our time if we train a new model.\n",
        "\n",
        "The paper we are basing our work on trains the model using not only the 5 digits, but also the length of the digits, we will now define a function to get us this information for each sample in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYbC4Q4M10S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(filepath, dataframe, maxlength=5):\n",
        "    \"\"\"\n",
        "\n",
        "    This function will return the categorical (one-hot) representation of 6 digits \n",
        "    that will be used to train our model.\n",
        "    \n",
        "    The first is the length of the house number for a given filepath and then one digit\n",
        "    for each of the 5 possible spots we are trying to predict, with 0 being \"more than 5\" for length\n",
        "    and blank for the individual digits.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    fn = filepath.split('/')[-1].split('.')[0]\n",
        "\n",
        "    label = dataframe.loc[int(fn) - 1].label\n",
        "\n",
        "    l = np.zeros(maxlength+1)\n",
        "    try:\n",
        "        l[len(label)] = 1\n",
        "    except:\n",
        "        l[0] = 1\n",
        "\n",
        "    y = np.zeros((5, 11), dtype=int)\n",
        "\n",
        "    for i in range(5):\n",
        "        try:\n",
        "            y[i][int(label[i])] = 1\n",
        "        except:\n",
        "            y[i][0] = 1\n",
        "\n",
        "    return [l, y[0], y[1], y[2], y[3], y[4]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oICauw9X10S-",
        "colab_type": "text"
      },
      "source": [
        "We also need to define a new function to convert back our label to a format we can understand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8yymPnz10S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_convert_label(label):\n",
        "    l = label[0]\n",
        "    labels = label[1:]\n",
        "    n_label = \"\"\n",
        "    for digit in labels:\n",
        "        if np.argmax(digit) == 0:\n",
        "            n_digit = \"\"\n",
        "        elif np.argmax(digit) == 10:\n",
        "            n_digit = \"0\"\n",
        "        else:\n",
        "            n_digit = str(np.argmax(digit))\n",
        "        n_label += n_digit\n",
        "    return n_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NDpYaP510TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test if everything works\n",
        "# print (get_label(train_filenames[100], trn_data))\n",
        "print \"converted label: \", new_convert_label(get_label(train_filenames[10], trn_data))\n",
        "plt.imshow(generate_crop(train_filenames[10], trn_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtP1QQt_10TG",
        "colab_type": "text"
      },
      "source": [
        "#### Another Generator\n",
        "\n",
        "Similarly to what we did on the first step, we will define a generator that will pass a random crop of the image and all the labels to our new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5GsbvB910TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_generator(filepath_list, dataframe, batch_size=32, crop_sz=(64, 64),\n",
        "                  shuffle_data=True, random_crop=True, return_labels=True):\n",
        "    \"\"\"\n",
        "    This generator receives a lisit of filenames from the SVHN dataset and a pandas dataframe\n",
        "    with the label information and returns a random crop of the image and the one-hot encoding\n",
        "    of the labels so we can pass it directly to Keras.\n",
        "\n",
        "    Input:\n",
        "    filepath_list - list with path to SVHN images.\n",
        "    dataframe - pandas dataframe with information about each image.\n",
        "\n",
        "    Arguments:\n",
        "    batch_size - size of the mini batch\n",
        "\n",
        "    Outputs:\n",
        "    X_train and y_train\n",
        "    \"\"\"\n",
        "\n",
        "    num_samples = len(filepath_list)\n",
        "    filelist = copy.copy(filepath_list)\n",
        "\n",
        "    if shuffle_data:\n",
        "        shuffle(filelist)\n",
        "\n",
        "    while True:  # Loop forever so the generator never terminates\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            batch_samples = filelist[offset:offset + batch_size]\n",
        "\n",
        "            if shuffle_data:\n",
        "                shuffle(batch_samples)\n",
        "\n",
        "            images = []\n",
        "            length = []\n",
        "            digits = []\n",
        "\n",
        "            for batch_sample in batch_samples:\n",
        "                img = generate_crop(batch_sample, dataframe, crop_sz=crop_sz, random_crop=random_crop)\n",
        "                y = np.zeros((5, 11), dtype='int')\n",
        "                [l, y[0, :], y[1, :], y[2, :], y[3, :], y[4, :]] = get_label(batch_sample, dataframe)\n",
        "            \n",
        "                images.append(img)\n",
        "                length.append(l)\n",
        "                digits.append(y)\n",
        "\n",
        "            X_train = np.array(images)\n",
        "            if len(X_train.shape) == 3:\n",
        "                X_train = np.expand_dims(X_train, -1)\n",
        "\n",
        "            y_temp = np.array(digits)\n",
        "            l = np.array(length)\n",
        "\n",
        "            y1 = y_temp[:, 0, :]\n",
        "            y2 = y_temp[:, 1, :]\n",
        "            y3 = y_temp[:, 2, :]\n",
        "            y4 = y_temp[:, 3, :]\n",
        "            y5 = y_temp[:, 4, :]\n",
        "            \n",
        "            if return_labels:\n",
        "                yield X_train, [l, y1, y2, y3, y4, y5]\n",
        "            else:\n",
        "                yield X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWmvmouV10TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create samples to test the generator\n",
        "i = 0\n",
        "for a, b in new_generator(train_filenames, trn_data, batch_size=25): \n",
        "    test_imgs = a\n",
        "    test_lbls = b\n",
        "    \n",
        "    i += 1\n",
        "    \n",
        "    if i > 1:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3097DQL10TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows_to_plot = 5\n",
        "cols_to_plot = 5\n",
        "\n",
        "f = plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i in range(rows_to_plot * cols_to_plot):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.title(new_convert_label([test_lbls[0][i], test_lbls[1][i], test_lbls[2][i], \n",
        "                                 test_lbls[3][i], test_lbls[4][i], test_lbls[5][i]]))\n",
        "    plt.imshow(test_imgs[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2620hkZ10TL",
        "colab_type": "text"
      },
      "source": [
        "#### Model\n",
        "\n",
        "This time we can define the model exactly as proposed on the literature, given that our input images are also with the same dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUPt8wa10TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on Model from: http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf\n",
        "\n",
        "def get_new_model(input_shape=(54, 54, 3), p=0.5, n_class=11, n_len=6):\n",
        "\n",
        "    inputs = Input(((input_shape[0], input_shape[1], input_shape[2])))\n",
        "    \n",
        "    x = BatchNormalization()(inputs)\n",
        "    x = Convolution2D(48, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p/4)(x)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(64, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p/4)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(128, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p/2)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(160, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p/2)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p)(x)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(p)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
        "    x = Dropout(p)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(3072, activation='relu')(x)\n",
        "    x = Dense(3072, activation='relu')(x)\n",
        "\n",
        "    l = Dense(n_len, activation='softmax')(x)\n",
        "    c1 = Dense(n_class, activation='softmax')(x)\n",
        "    c2 = Dense(n_class, activation='softmax')(x)\n",
        "    c3 = Dense(n_class, activation='softmax')(x)\n",
        "    c4 = Dense(n_class, activation='softmax')(x)\n",
        "    c5 = Dense(n_class, activation='softmax')(x)\n",
        "    \n",
        "    output = [l, c1, c2, c3, c4, c5]\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7aKDTST10TP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = get_new_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF_Rm32u10TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8UcUJyN10TW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_convert_output(model_output):\n",
        "    l = model_output[0]\n",
        "    digits = np.array(model_output[1:]).swapaxes(0, 1)\n",
        "    labels = []\n",
        "    for i in range(len(l)):\n",
        "        label = new_convert_label(([l[i]], digits[i, 0, :], digits[i, 1, :],\n",
        "                                  digits[i, 2, :], digits[i, 3, :], digits[i, 4, :]))\n",
        "        labels.append(label)\n",
        "\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGSLqzdU10TX",
        "colab_type": "text"
      },
      "source": [
        "#### Overfit new model on small sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ZN9kqG10TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=1e-3)\n",
        "new_model.compile(optimizer, loss='categorical_crossentropy')\n",
        "new_model.fit(test_imgs, test_lbls, epochs=1000, verbose=0)\n",
        "teste_out = new_model.predict(test_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EfyInIM10Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = new_convert_output(teste_out)\n",
        "\n",
        "rows_to_plot = 5\n",
        "cols_to_plot = 5\n",
        "\n",
        "f = plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, (pred, img) in enumerate(zip(output, test_imgs)):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.title(\"Predicted: \" + pred)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtvjroX-10Tc",
        "colab_type": "text"
      },
      "source": [
        "This time the model required 1,000 epochs on the sample dataset to get to a \"reasonable\" point. It's still not overfitting completely, but it's learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z79CWPUU10Td",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FODyN4k710Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into training and validation, using 80% for training and 20% for validation:\n",
        "trn_filenames, val_filenames = train_test_split(train_filenames, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGB8yFkH10Ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = get_new_model()\n",
        "optimizer = Adam(lr=1e-3)\n",
        "new_model.compile(optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "callbacks = [ModelCheckpoint('./models/new_model.{epoch:02d}-{val_loss:.2f}.hdf5')]\n",
        "\n",
        "trn_generator = new_generator(trn_filenames, trn_data, batch_size=128)\n",
        "val_generator = new_generator(val_filenames, trn_data, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg4NBytS10Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.fit_generator(trn_generator,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=200,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=200,\n",
        "                    callbacks=callbacks,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1SjI6Vm10Tn",
        "colab_type": "text"
      },
      "source": [
        "#### Save  and load our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW0QQxKY10To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new_model.save_weights('./models/step2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUjWcm7910Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.load_weights('./models/step2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5xml68g10Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teste_out = new_model.predict(test_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdI7QpEN10Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = new_convert_output(teste_out)\n",
        "\n",
        "rows_to_plot = 5\n",
        "cols_to_plot = 5\n",
        "\n",
        "f = plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, (pred, img) in enumerate(zip(output, test_imgs)):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.title(\"Predicted: \" + pred)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx0KGhpn10Tu",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMO-OuVD10Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tst_filenames = glob(dataset_path + '/test/*.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWyVbVHA10Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tst_imgs = []\n",
        "tst_labels = []\n",
        "for filename in tst_filenames:\n",
        "    img = generate_crop(filename, tst_data, crop_sz=(54, 54), random_crop=False)\n",
        "    lbl = get_label(filename, tst_data)\n",
        "    n_lbl = new_convert_label(lbl)\n",
        "    tst_labels.append(n_lbl)\n",
        "    tst_imgs.append(img)\n",
        "\n",
        "tst_imgs = np.array(tst_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPl8Iclk10Ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check that we are getting the imgs and labels correctly\n",
        "rows_to_plot = 5\n",
        "cols_to_plot = 5\n",
        "\n",
        "f = plt.figure(figsize=(16, 16))\n",
        "\n",
        "for i, fn in enumerate(np.random.choice(len(tst_filenames), rows_to_plot * cols_to_plot)):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.imshow(tst_imgs[fn])\n",
        "    plt.title(tst_labels[fn])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rSxQKtj10T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tst_generator = new_generator(tst_filenames, tst_data, batch_size=128, crop_sz=(54, 54),\n",
        "#                              shuffle_data=False, random_crop=False, return_labels=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KowxRFDS10T2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tst_pred = new_model.predict_generator(tst_generator, steps=len(tst_filenames) // 128 + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t74chp9Y10T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tst_pred = new_model.predict(tst_imgs, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJJH-Qx10T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_labels = new_convert_output(tst_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QQx8VF310T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tst_accuracy = accuracy_score(tst_labels, pred_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws0NVcFc10T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print \"Accuracy: \", np.round(tst_accuracy*100, 1), \"%\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUJs3BIz10UA",
        "colab_type": "text"
      },
      "source": [
        "This is still significantly below the 98% of human accuracy, but in Goodfellow et al. they trained 10 models in parallel for 6 days to achieve human level accuracy. Our version was trained for 20 epochs, where in each epoch it would see approximately 10 different crops of each image.\n",
        "\n",
        "If we continued to optimize the model weights, I am positive we would have better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmeP2wRd10UA",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "146fGmnb10UB",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "### Testing the first model on the SVHN dataset\n",
        "\n",
        "At this point I realized that I should have also explored the labels from the SVHN dataset and not only the images when creating our synthetic dataset.\n",
        "\n",
        "The fact that the labels were incompatible made large-scaling impossible without developing a label-conversion function and before doing that I decided to manually test the model in a few selected images to see if it was worth investing the time to convert the labels.\n",
        "\n",
        "The only processing steps on the new images were to scale to 28 x 140 pixels and convert to gray scale, as that is how our model was trained.\n",
        "\n",
        "Surprisingly the model was not able to generalize at all, it was incorrect on 100% of the test images. I was obviously expecting a decrease in performance but 0% accuracy was definitely an unpleasant surprise.\n",
        "\n",
        "Due to the incompatibility of labels and input size between datasets, fine tuning would be more difficult than training a new model. Too bad, as we ended up missing an important part of the purpose of the synthetic dataset, although all this was not completely wasted, we validated that the model architecture we chose is right for the problem at hand.\n",
        "\n",
        "### Training 2.0\n",
        "\n",
        "The SVHN data set provides coordinates of bounding boxes for each digit in an image, but since the purpose of our pipeline is to identify the whole street number in one shot, we needed to pass a cropped version of the image with all numbers in it, and not much more.\n",
        "\n",
        "We followed the suggested training methodology from Goodfellow et al.\n",
        "\n",
        "- Based on the provided bounding boxes, find another box that will contain all digits on the image\n",
        "\n",
        "- Expand this bounding box by 30% in each direction and crop the image to this bounding box\n",
        "\n",
        "- Resize the cropped image to 64 x 64 pixels\n",
        "\n",
        "- Random crop a 54 x 54 sample from the cropped image\n",
        "\n",
        "Training was again assisted by a python generator, that randomly cropped the 64 x 64 pixel image into 54 x 54 patches, aiming to increase the amount of training data. At this time 20% of the dataset was put aside for validation.\n",
        "\n",
        "The accuracy of the model on a realistic dataset is 83%, but the accuracy was still improving when we decided to interrupt the optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k27VvQKj10UB",
        "colab_type": "text"
      },
      "source": [
        "### Question 5\n",
        "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHn0Nvsw10UC",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "Knowing that we would need to train a new model from scratch gave me the freedom to implement some improvements to the architecture. I added back to the model the two convolutional blocks that were initially removed, I also increased the number of hidden units in the last two fully connected layers and added a new branch of softmax classifier to predict the length of the sequence of digits.\n",
        "\n",
        "Aside from these few adjustments, the model architecture is very similar to our first one and can be seen below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T352wL1B10UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVG(model_to_dot(new_model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uft2Ta-p10UF",
        "colab_type": "text"
      },
      "source": [
        "### Question 6\n",
        "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7-wjZDD10UF",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "My initial result was probably very close to 0, as I tried to use the pre-trained weights of my model on step 1, but didn't have an easy way of converting the labels of the second dataset to measure it's performance. Since the initial exploration was already indicating that it would have a poor performance, I decided to train a larger model, following the suggestion of the literature we based this work on.\n",
        "\n",
        "At the end of 20 epochs the accuracy of our model was 83% - still significantly below human accuracy, but it is a strong indicator that the model is able to learn and if trained for longer, it could achieve results similar to what was observed by the authors of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0rR3pOe10UF",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "## Step 3: Test a Model on Newly-Captured Images\n",
        "\n",
        "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLu3uujr10UG",
        "colab_type": "text"
      },
      "source": [
        "### Implementation\n",
        "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8STK_kn10UG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "### Your code implementation goes here.\n",
        "### Feel free to use as many code cells as needed.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFozo1wZ10UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = []\n",
        "new_filenames = []\n",
        "\n",
        "filelist = os.listdir('./data/')\n",
        "\n",
        "for file in filelist:\n",
        "\n",
        "    try:\n",
        "        img = cv2.imread('./data/' + file, cv2.IMREAD_COLOR)\n",
        "    except:\n",
        "        img = None\n",
        "\n",
        "    if img is not None:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (54, 54))\n",
        "        new_images.append(img)\n",
        "        new_filenames.append(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st_lMQwA10UM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = np.array(new_images)\n",
        "test_new_preds = new_model.predict(new_images)\n",
        "new_pred_labels = new_convert_output(test_new_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7ipLOwIO10UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows_to_plot = 5\n",
        "cols_to_plot = 2\n",
        "\n",
        "f = plt.figure(figsize=(12, 20))\n",
        "\n",
        "for i, (pred, img) in enumerate(zip(new_pred_labels, new_images)):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.title(\"Predicted: \" + pred)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRpts_LB10UU",
        "colab_type": "text"
      },
      "source": [
        "We will now pass on the cropped numbers to see if it gets any better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X-DQwi_10UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = []\n",
        "new_filenames = []\n",
        "\n",
        "filelist = os.listdir('./data/small/')\n",
        "\n",
        "for file in filelist:\n",
        "\n",
        "    try:\n",
        "        img = cv2.imread('./data/small/' + file, cv2.IMREAD_COLOR)\n",
        "    except:\n",
        "        img = None\n",
        "\n",
        "    if img is not None:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (54, 54))\n",
        "        new_images.append(img)\n",
        "        new_filenames.append(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2FEMFX10UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = np.array(new_images)\n",
        "test_new_preds = new_model.predict(new_images)\n",
        "new_pred_labels = new_convert_output(test_new_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqZhVViq10Ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows_to_plot = 5\n",
        "cols_to_plot = 2\n",
        "\n",
        "f = plt.figure(figsize=(12, 20))\n",
        "\n",
        "for i, (pred, img) in enumerate(zip(new_pred_labels, new_images)):\n",
        "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
        "    plt.title(\"Predicted: \" + pred)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUUhsYfP10Uc",
        "colab_type": "text"
      },
      "source": [
        "Ah! Much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR4IU4EX10Uc",
        "colab_type": "text"
      },
      "source": [
        "### Question 7\n",
        "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjHw3EMJ10Uc",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "The pictures were taking from a long distance, and when they were scaled down the algorithm failed to predict in all 5 cases. When we passed the cropped number it actually had a performance similar to what we found above ~80% (4 out of 5 numbers were correctly labeled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbm9VXIS10Ud",
        "colab_type": "text"
      },
      "source": [
        "### Question 8\n",
        "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPkLyAXr10Ud",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "Our model only performed well when the images were cropped in a similar way as the images we passed on to the model during training. Which is in line with what should be expected. We trained the model using an easier dataset where the numbers were already located for it and it's unreasonable to expect that the model would be able to generalize to images with a lot more information.\n",
        "\n",
        "Another issue is that we trained the model on a super small patch of image 54 x 54 pixels, and to use an image that was captured with a smartphone we needed to downsize it so much that any detail was lost. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbFzgTuw10Ue",
        "colab_type": "text"
      },
      "source": [
        "### Optional: Question 9\n",
        "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dShIGa0K10Uf",
        "colab_type": "text"
      },
      "source": [
        "**Answer:** Leave blank if you did not complete this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCKBnH710Uf",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "### Step 4: Explore an Improvement for a Model\n",
        "\n",
        "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK2dyOx810Ug",
        "colab_type": "text"
      },
      "source": [
        "### Implementation\n",
        "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne8fsxmg10Ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "### Your code implementation goes here.\n",
        "### Feel free to use as many code cells as needed.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeECFwso10Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_filenames, val_filenames = train_test_split(train_filenames, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upx3oKCw10Uj",
        "colab_type": "text"
      },
      "source": [
        "#### Get bounding boxes to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvgPezIN10Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bbox(filepath, dataframe, verbose=0):\n",
        "    \"\"\"\n",
        "    This function expects a filepath of an image and a dataframe with information for the bounding boxes\n",
        "    and will return a larger bounding box that wraps all the digits on the house number.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # 1 - find bounding box for whole street number\n",
        "    fn = filepath.split('/')[-1].split('.')[0]\n",
        "\n",
        "    left = np.min(dataframe.loc[int(fn) - 1].left).astype(np.uint)\n",
        "    top = np.min(dataframe.loc[int(fn) - 1].top).astype(np.uint)\n",
        "    bottom = (np.max(dataframe.loc[int(fn) - 1].top) + np.max(dataframe.loc[int(fn) - 1].height)).astype(np.uint)\n",
        "    right = (np.max(dataframe.loc[int(fn) - 1].left) + np.max(dataframe.loc[int(fn) - 1].width)).astype(np.uint)\n",
        "\n",
        "    if verbose>0:\n",
        "        print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
        "\n",
        "    \n",
        "    return left, right, top, bottom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ92rQvL10Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_rect(bb, color='red'):\n",
        "    return plt.Rectangle((bb[0], bb[2]), bb[1] - bb[0], bb[3] - bb[2], color=color, fill=False, lw=3)\n",
        "\n",
        "def show_bb_raw(filepath, dataframe):\n",
        "    bb = get_bbox(filepath, dataframe)\n",
        "    plt.imshow(Image.open(filepath, mode='r'))\n",
        "    plt.gca().add_patch(create_rect(bb))\n",
        "\n",
        "def show_bb(img, bb, bb_2=None):\n",
        "    plt.imshow(img)\n",
        "    plt.gca().add_patch(create_rect(bb))\n",
        "    if bb_2 is not None:\n",
        "        plt.gca().add_patch(create_rect(bb_2, 'yellow'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKdDZLMX10Uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_bb_raw(val_filenames[5587], trn_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQsjsECc10Uq",
        "colab_type": "text"
      },
      "source": [
        "#### Rescaling images and bounding boxes\n",
        "\n",
        "Since we have images with various dimensions, we will need to rescale them to the same size in order to feed our model. We will also need to apply the same transformation to the bounding boxes coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztj2q0b410Ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_imgs(filepath, dataframe, return_bbox=True, target_sz=(64, 64), verbose=0):\n",
        "\n",
        "    # 1 - open the image and store img dimensions\n",
        "    img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_h = float(img.shape[0])\n",
        "    img_w = float(img.shape[1])\n",
        "\n",
        "    if verbose>0:\n",
        "        print \"img_h: \", img_h, \"    img_w: \", img_w, \"\\n\"\n",
        "        print \"tgt_sz_0: \", target_sz[0], \"    tgt_sz_1: \", target_sz[1], \"\\n\"\n",
        "\n",
        "    # 2 - resize image\n",
        "    rescaled = cv2.resize(img, target_sz)\n",
        "    \n",
        "    if return_bbox:\n",
        "\n",
        "        # 3 - find bounding box for whole street number\n",
        "        fn = filepath.split('/')[-1].split('.')[0]\n",
        "\n",
        "        left = np.min(dataframe.loc[int(fn) - 1].left)\n",
        "        top = np.min(dataframe.loc[int(fn) - 1].top)\n",
        "        bottom = (np.max(dataframe.loc[int(fn) - 1].top) + np.max(dataframe.loc[int(fn) - 1].height))\n",
        "        right = (np.max(dataframe.loc[int(fn) - 1].left) + np.max(dataframe.loc[int(fn) - 1].width))\n",
        "        \n",
        "        if verbose>0:\n",
        "            print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
        "\n",
        "        # 4 - Convert bounding box to new image size\n",
        "        h_ratio = img_h / target_sz[0]\n",
        "        w_ratio = img_w / target_sz[1]\n",
        "\n",
        "        if verbose>0:\n",
        "            print \"h_ratio: \", h_ratio, \"    w_ratio: \", w_ratio, \"\\n\"\n",
        "        \n",
        "        left = np.max((0, np.floor_divide(left, w_ratio)))\n",
        "        right = np.min((target_sz[1], np.floor_divide(right, w_ratio)))\n",
        "        top = np.max((0, np.floor_divide(top, h_ratio)))\n",
        "        bottom = np.min((target_sz[0], np.floor_divide(bottom, h_ratio)))\n",
        "\n",
        "        if verbose>0:\n",
        "            print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
        "\n",
        "        return rescaled, [left, right, top, bottom]\n",
        "\n",
        "    else:\n",
        "        return rescaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLuCj8Ad10Us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"trn_bbox_imgs = []\n",
        "trn_bbox_box = []\n",
        "target_sz = (64, 64)\n",
        "\n",
        "for filename in trn_filenames:\n",
        "    img, bb = resize_imgs(filename, trn_data, target_sz=(64, 64), verbose=0)\n",
        "    trn_bbox_imgs.append(img)\n",
        "    trn_bbox_box.append(bb)\n",
        "\n",
        "trn_bbox_box = np.array(trn_bbox_box)\n",
        "trn_bbox_imgs = np.array(trn_bbox_imgs)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODNjB-4_10Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"val_bbox_imgs = []\n",
        "val_bbox_box = []\n",
        "target_sz = (64, 64)\n",
        "\n",
        "for filename in val_filenames:\n",
        "    img, bb = resize_imgs(filename, trn_data, target_sz=(64, 64), verbose=0)\n",
        "    val_bbox_imgs.append(img)\n",
        "    val_bbox_box.append(bb)\n",
        "\n",
        "val_bbox_box = np.array(val_bbox_box)\n",
        "val_bbox_imgs = np.array(val_bbox_imgs)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDMI6GBZ10Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"# Save images and bboxes to pickle\n",
        "f = open('trn_filenames.pickle', 'wb')\n",
        "pickle.dump(trn_filenames, f, pickle.HIGHEST_PROTOCOL)\n",
        "f.close()\n",
        "\n",
        "f = open('val_filenames.pickle', 'wb')\n",
        "pickle.dump(val_filenames, f, pickle.HIGHEST_PROTOCOL)\n",
        "f.close()\n",
        "\n",
        "f = open('trn_bbox_box.pickle', 'wb')\n",
        "pickle.dump(trn_bbox_box, f, pickle.HIGHEST_PROTOCOL)\n",
        "f.close()\n",
        "\n",
        "f = open('trn_bbox_imgs.pickle', 'wb')\n",
        "pickle.dump(trn_bbox_imgs, f, pickle.HIGHEST_PROTOCOL)\n",
        "f.close()\n",
        "\n",
        "f = open('val_bbox_box.pickle', 'wb')\n",
        "pickle.dump(val_bbox_box, f, pickle.HIGHEST_PROTOCOL)\n",
        "f.close()\n",
        "\n",
        "f = open('val_bbox_imgs.pickle', 'wb')\n",
        "pickle.dump(val_bbox_imgs, f, pickle.HIGHEST_PROTOCOL)\n",
        "f.close()\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKTqjsgl10Uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Pickles\n",
        "f = open('trn_filenames.pickle', 'r')\n",
        "trn_filenames = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('val_filenames.pickle', 'r')\n",
        "val_filenames = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('trn_bbox_box.pickle', 'r')\n",
        "trn_bbox_box = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('trn_bbox_imgs.pickle', 'r')\n",
        "trn_bbox_imgs = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('val_bbox_box.pickle', 'r')\n",
        "val_bbox_box = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open('val_bbox_imgs.pickle', 'r')\n",
        "val_bbox_imgs = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "trn_bbox_box = np.array(trn_bbox_box, dtype=float)\n",
        "trn_bbox_imgs = np.array(trn_bbox_imgs, dtype=float)\n",
        "val_bbox_box = np.array(val_bbox_box, dtype=float)\n",
        "val_bbox_imgs = np.array(val_bbox_imgs, dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLNIZ_ab10U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cvt_bbox(bbox):\n",
        "    \"\"\"\n",
        "    Input: bounding box: Left, Right, Top, Bottom\n",
        "    Output: x0, y0, width, height\n",
        "    \"\"\"\n",
        "    \n",
        "    left, right, top, bottom = bbox\n",
        "    \n",
        "    x0 = left\n",
        "    y0 = top\n",
        "    width = right - left\n",
        "    height = bottom - top\n",
        "    \n",
        "    return x0, y0, width, height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCamIxQO10U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trn_bbox_box_new = [cvt_bbox(box) for box in trn_bbox_box]\n",
        "trn_bbox_imgs /= 255\n",
        "trn_bbox_imgs -= 0.5\n",
        "\n",
        "#val_bbox_box_new  = [cvt_bbox(box) for box in val_bbox_box]\n",
        "val_bbox_imgs /= 255\n",
        "val_bbox_imgs -= 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujSrFebB10U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref=777\n",
        "show_bb(trn_bbox_imgs[ref], trn_bbox_box[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xof9sCDm10U7",
        "colab_type": "text"
      },
      "source": [
        "#### First attempt: Use the image and the coordinates of the bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNfRZLJg10U9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(((64, 64, 3)))\n",
        "\n",
        "x = BatchNormalization()(inputs)\n",
        "x = Convolution2D(64, 3, activation='relu', padding='same')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "x = Convolution2D(128, 3, activation='relu', padding='same')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "x = Convolution2D(256, 3, activation='relu', padding='same')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x_bb = Dense(4, name='bb')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZehIKZd10VB",
        "colab_type": "text"
      },
      "source": [
        "#### Overfit small sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogAn9Osk10VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model = Model([inputs], x_bb,)\n",
        "loc_model.compile(Adam(lr=0.001), loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrOMP_QF10VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model.fit(trn_bbox_imgs[0:5], trn_bbox_box[0:5], batch_size=5, epochs=50, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwaME7sI10VI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(loc_model.history.history['loss'], '-o')\n",
        "plt.legend(['trn_loss'], loc='upper right')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U-glFmC10VL",
        "colab_type": "text"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzvXFugy10VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model = Model([inputs], x_bb,)\n",
        "loc_model.compile(Adam(lr=0.001), loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Ct5Jf210VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model.fit(trn_bbox_imgs, trn_bbox_box, batch_size=32, epochs=5,\n",
        "              validation_data=(val_bbox_imgs, val_bbox_box), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVKlG9qK10VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(loc_model.history.history['loss'], '-o')\n",
        "plt.plot(loc_model.history.history['val_loss'], '-o')\n",
        "plt.legend(['trn_loss', 'val_loss'], loc='upper right')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgonrd-k10VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_box = loc_model.predict(val_bbox_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oSmwxVt10VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_ref=8\n",
        "show_bb((val_bbox_imgs[val_ref] + 0.5) * 255, val_bbox_box[val_ref], pred_box[val_ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OEa8I3s10VX",
        "colab_type": "text"
      },
      "source": [
        "#### Second attempt: Transform bounding boxes into image masks and use a better loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-CmRQ3l10VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mask_seg(img, bbox, value=1.):\n",
        "    \n",
        "    img_mask = np.zeros_like(img[:,:,0])\n",
        "    \n",
        "    x_min, x_max, y_min, y_max = bbox\n",
        "    \n",
        "    x_min = np.round(x_min,0).astype(np.uint8)\n",
        "    x_max = np.round(x_max,0).astype(np.uint8)\n",
        "    y_min = np.round(y_min,0).astype(np.uint8)\n",
        "    y_max = np.round(y_max,0).astype(np.uint8)\n",
        "\n",
        "    img_mask[y_min:y_max, x_min:x_max]= 1. * value\n",
        "\n",
        "    img_mask = np.reshape(img_mask,(np.shape(img_mask)[0],np.shape(img_mask)[1],1))\n",
        "    \n",
        "    return img_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k5S1Yi010VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_im_mask(im,im_mask):\n",
        "    ### Function to plot image mask \n",
        "    \n",
        "    im = np.array(im,dtype=np.uint8)\n",
        "    im_mask = np.array(im_mask,dtype=np.uint8)\n",
        "    plt.figure(figsize=(24,12))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(im)\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(im_mask[:,:,0])\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(cv2.bitwise_and(im,im,mask=im_mask));\n",
        "    plt.axis('off')\n",
        "    plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leXSRwjl10Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_trn_mask = np.array([get_mask_seg(img,bbox, value=1.) for (img,bbox) in zip(trn_bbox_imgs, trn_bbox_box) ])\n",
        "\n",
        "loc_val_mask = np.array([get_mask_seg(img,bbox, value=1.) for (img,bbox) in zip(val_bbox_imgs, val_bbox_box) ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psNk4XyD10Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 777\n",
        "plot_im_mask(trn_bbox_imgs[ref], loc_trn_mask[ref] * 255.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-0grF5110Vg",
        "colab_type": "text"
      },
      "source": [
        "#### IOU Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-FiF14d10Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### IOU or dice coeff calculation measures the similarity in both area and position of the two bounding boxes\n",
        "\n",
        "def IOU_calc(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    \n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def IOU_loss(y_true, y_pred):\n",
        "    return -IOU_calc(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEbJmjei10Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs2 = Input(((64, 64, 3)))\n",
        "\n",
        "x = BatchNormalization()(inputs2)\n",
        "x = Convolution2D(64, 3, activation='relu', padding='same')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "x = Convolution2D(128, 3, activation='relu', padding='same')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = BatchNormalization()(x)\n",
        "x = Convolution2D(256, 3, activation='relu', padding='same')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output2 = Convolution2D(1, 3, activation='sigmoid', padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PMAlmwT10Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model2 = Model([inputs2], output2,)\n",
        "loc_model2.compile(Adam(lr=0.001), loss=IOU_loss, metrics=[IOU_calc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg5n3C-f10Vm",
        "colab_type": "text"
      },
      "source": [
        "#### Overfit small sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C40wJ1m10Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model2.fit(trn_bbox_imgs[0:5], loc_trn_mask[0:5], batch_size=5, epochs=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7s3R8sB10Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(loc_model2.history.history['loss'], '-o')\n",
        "plt.legend(['trn_loss'], loc='upper right')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax94ABSs10Vp",
        "colab_type": "text"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UW-I0t210Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model2 = Model([inputs2], output2,)\n",
        "loc_model2.compile(Adam(lr=0.001), loss=IOU_loss, metrics=[IOU_calc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBKRfq1K10Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model2.fit(trn_bbox_imgs, loc_trn_mask, batch_size=32, epochs=2,\n",
        "              validation_data=(val_bbox_imgs, loc_val_mask), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOTQYvIb10Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(loc_model2.history.history['loss'], '-o')\n",
        "plt.plot(loc_model2.history.history['val_loss'], '-o')\n",
        "plt.legend(['trn_loss', 'val_loss'], loc='upper right')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqI_KzuK10Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_box2 = loc_model2.predict(val_bbox_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQgC5RDr10Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(loc_val_mask[2][:,:,0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51HYND610Vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(pred_box2[2][:,:,0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU6nsZ0S10V1",
        "colab_type": "text"
      },
      "source": [
        "#### Save  and load our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_R8lALM10V1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loc_model.save_weights('./models/locator.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VENZ8KZ10V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loc_model.load_weights('./models/locator.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zlq7SRd10V5",
        "colab_type": "text"
      },
      "source": [
        "Still not amazing, but with this approach we can try fancier networks, like U-net.\n",
        "[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n",
        "\n",
        "We will need to change it a little bit because our input image is a lot smaller than the ones they used on their model, but the concept will be the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lBw6uYH10V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet(input_shape=(64, 64, 3)):\n",
        "    \n",
        "    inputs = Input(((input_shape[0], input_shape[1], input_shape[2])))\n",
        "    \n",
        "    c_1 = Convolution2D(32, 3, activation='relu', padding='same', name='conv1_a')(inputs)\n",
        "    c_1 = Convolution2D(32, 3, activation='relu', padding='same', name='conv1_b')(c_1)\n",
        "    p_1 = MaxPooling2D(pool_size=(2, 2), name='pool1')(c_1)\n",
        "\n",
        "    c_2 = Convolution2D(64, 3, activation='relu', padding='same', name='conv2_a')(p_1)\n",
        "    c_2 = Convolution2D(64, 3, activation='relu', padding='same', name='conv2_b')(c_2)\n",
        "    p_2 = MaxPooling2D(pool_size=(2, 2), name='pool2')(c_2)\n",
        "\n",
        "    c_3 = Convolution2D(128, 3, activation='relu', padding='same', name='conv3_a')(p_2)\n",
        "    c_3 = Convolution2D(128, 3, activation='relu', padding='same', name='conv3_b')(c_3)\n",
        "    p_3 = MaxPooling2D(pool_size=(2, 2), name='pool3')(c_3)\n",
        "\n",
        "    c_4 = Convolution2D(256, 3, activation='relu', padding='same', name='conv4_a')(p_3)\n",
        "    c_4 = Convolution2D(256, 3, activation='relu', padding='same', name='conv4_b')(c_4)\n",
        "    p_4 = MaxPooling2D(pool_size=(2, 2), name='pool4')(c_4)\n",
        "\n",
        "    c_5 = Convolution2D(512, 3, activation='relu', padding='same', name='conv5_a')(p_4)\n",
        "    c_5 = Convolution2D(512, 3, activation='relu', padding='same', name='conv5_b')(c_5)\n",
        "\n",
        "    up_6 = concatenate([UpSampling2D(size=(2, 2))(c_5), c_4])\n",
        "    c_6 = Convolution2D(256, 3, activation='relu', padding='same', name='conv6_a')(up_6)\n",
        "    c_6 = Convolution2D(256, 3, activation='relu', padding='same', name='conv6_b')(c_6)\n",
        "\n",
        "    up_7 = concatenate([UpSampling2D(size=(2, 2))(c_6), c_3])\n",
        "    c_7 = Convolution2D(128, 3, activation='relu', padding='same', name='conv7_a')(up_7)\n",
        "    c_7 = Convolution2D(128, 3, activation='relu', padding='same', name='conv7_b')(c_7)\n",
        "\n",
        "    up_8 = concatenate([UpSampling2D(size=(2, 2))(c_7), c_2])\n",
        "    c_8 = Convolution2D(64, (3, 3), activation='relu', padding='same', name='conv8_a')(up_8)\n",
        "    c_8 = Convolution2D(64, (3, 3), activation='relu', padding='same', name='conv8_b')(c_8)\n",
        "\n",
        "    up_9 = concatenate([UpSampling2D(size=(2, 2))(c_8), c_1])\n",
        "    c_9 = Convolution2D(32, (3, 3), activation='relu', padding='same', name='conv9_a')(up_9)\n",
        "    c_9 = Convolution2D(32, (3, 3), activation='relu', padding='same', name='conv9_b')(c_9)\n",
        "\n",
        "    c_10 = Convolution2D(1, 1, activation='sigmoid')(c_9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[c_10])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhmhkzae10V7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet_model = unet()\n",
        "unet_model.compile(Adam(lr=1e-4), loss=IOU_loss, metrics=[IOU_calc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "440Dypik10V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet_model.fit(trn_bbox_imgs, loc_trn_mask, batch_size=32, epochs=15,\n",
        "              validation_data=(val_bbox_imgs, loc_val_mask), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBdAstE010WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(unet_model.history.history['loss'], '-o')\n",
        "plt.plot(unet_model.history.history['val_loss'], '-o')\n",
        "plt.legend(['trn_loss', 'val_loss'], loc='upper right')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp6BCQs210WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_box_unet = unet_model.predict(val_bbox_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNnoKY3q10WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(loc_val_mask[2][:,:,0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDKt_6KY10WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(pred_box_unet[1][:,:,0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6HS06eV10WX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_im_mask(val_bbox_imgs[500], pred_box_unet[500] * 255.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qORgtaAM10Wb",
        "colab_type": "text"
      },
      "source": [
        "#### Save  and load our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqlsozk710Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unet_model.save_weights('./models/unet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAAOpJJH10Wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet_model.load_weights('./models/unet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh1VwYel10Wh",
        "colab_type": "text"
      },
      "source": [
        "### Question 10\n",
        "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyVJ2IKS10Wh",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "The last version of my localizer seems to be performing well on the realistic dataset. The accuracy of the predicted bounding boxes are a little under 90% as measured by the Dice coefficient. \n",
        "\n",
        "The SVHN test dataset already includes the coordinates for the bounding boxes on the test set and this was used to assess the performance of the model on step 2. Had this information had not been provided it's safe to assume that the model would have performed significantly worse, as suggested by our test cases on step 3. In that scenario, using the number locator we just trained should bring our performance back to the levels we saw in our test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK9TP85T10Wi",
        "colab_type": "text"
      },
      "source": [
        "### Question 11\n",
        "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kojp4Dm10Wj",
        "colab_type": "text"
      },
      "source": [
        "**Answer:**\n",
        "Surprisingly the model was not able to generalize for the images that I used. I suspect that the poor results on the 64 x 64 pixels image is due to the loss of information you have when downsampling the original image.\n",
        "\n",
        "At 64  x 64 pixels it found the same \"blobs\" as probably the ones from where numbers were likely to be found, but the noise in the image ended up confusing the model.\n",
        "\n",
        "I also tried to use the same weights, but change the model input to 1024 x 1024 - given that this is a fully convolutional model, I assumed that the weights could be shared between models, but the results clearly show that they cannot.\n",
        "\n",
        "I suspect that given images that are more similar to the ones we have trained the model, it should perform better.\n",
        "\n",
        "I have provided the examples for both cases below: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pVAl2cz10Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = []\n",
        "new_filenames = []\n",
        "\n",
        "filelist = os.listdir('./data/')\n",
        "\n",
        "for file in filelist:\n",
        "\n",
        "    try:\n",
        "        img = cv2.imread('./data/' + file, cv2.IMREAD_COLOR)\n",
        "    except:\n",
        "        img = None\n",
        "\n",
        "    if img is not None:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (64, 64))\n",
        "        new_images.append(img)\n",
        "        new_filenames.append(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-xvhny210Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = np.array(new_images, dtype='float')\n",
        "proc_new_images = new_images / 255 - 0.5\n",
        "test_new_masks = unet_model.predict(proc_new_images, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NC27llO10Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 0 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpu9y0jx10Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 1 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i62BeHJs10Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 2 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xh_x9oz10W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 3 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjyQqfS10W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 4 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAZDbCd610W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = []\n",
        "new_filenames = []\n",
        "\n",
        "filelist = os.listdir('./data/')\n",
        "\n",
        "for file in filelist:\n",
        "\n",
        "    try:\n",
        "        img = cv2.imread('./data/' + file, cv2.IMREAD_COLOR)\n",
        "    except:\n",
        "        img = None\n",
        "\n",
        "    if img is not None:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (1024, 1024))\n",
        "        new_images.append(img)\n",
        "        new_filenames.append(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Do4ezda10W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet_large = unet(input_shape=(1024, 1024, 3))\n",
        "unet_large.load_weights('./models/unet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAudFf4q10XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_images = np.array(new_images, dtype='float')\n",
        "proc_new_images = new_images / 255 - 0.5\n",
        "test_new_masks = unet_large.predict(proc_new_images, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djveR4GR10XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 0 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BUo37u910XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 1 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygJ_yEtJ10XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 2 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDZKCu6s10XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 3 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTBbaJ3O10XM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref = 4 \n",
        "plot_im_mask(new_images[ref], test_new_masks[ref])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgUZCTaM10XO",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "## Optional Step 5: Build an Application or Program for a Model\n",
        "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
        "\n",
        "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
        "\n",
        "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wIH3dxg10XP",
        "colab_type": "text"
      },
      "source": [
        "### Optional Implementation\n",
        "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXQ0xNdy10XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "### Your optional code implementation goes here.\n",
        "### Feel free to use as many code cells as needed.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BQCP21O10XT",
        "colab_type": "text"
      },
      "source": [
        "### Documentation\n",
        "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09LYg9tv10XU",
        "colab_type": "text"
      },
      "source": [
        "_Write your documentation here._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_TgOPpP10XU",
        "colab_type": "text"
      },
      "source": [
        "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
        "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkWAWCH-aC5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
